{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类——从决策树开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类\n",
    "`分类（Classification）`:利用一个分类函数（又称`分类模型`、`分类器`），该模型能把数据映射到给定类别中的一个类,预测的变量`y`是离散的，预测的结果是否属于某一个类(例如：正确或错误)。分类任务就是确定对象属于哪个预定义的目标类。  \n",
    "生活中很多分类的例子： \n",
    "* 例1：判断邮件是否是垃圾邮件\n",
    "* 例2：根据核磁共振的结果判断肿瘤是良性的还是恶性的\n",
    "* 例3：信用卡交易是正常消费还是欺诈?\n",
    "* 例4：手写数字识别\n",
    "* 例5：对新闻进行分类：体育、财经、军事….\n",
    "* 例6：预测天气\n",
    "\n",
    "分类问题是监督学习的一个核心问题。  \n",
    "监督学习从数据中学习一个分类决策函数或分类模型，称为`分类器（classifier）`\n",
    "* 分类器对新的输入进行输出的预测，这个过程称为分类。\n",
    "* 学习与分类两个过程\n",
    "\n",
    "## 分类的评价指标\n",
    "分类问题常用的评价指标是`准确率(Accuracy)`、`精确率`（precision）与`召回率`（recall）\n",
    "* 准确率：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。\n",
    "计算公式：$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "缺点：在正负样本不平衡的情况下，这个指标有很大的缺陷。例如：给定一组测试样本共1100个实例，其中1000个是正类，剩余100个是负类。即使分类模型将所有实例均预测为正类，Accuracy也有90%以上，这样就没什么意义了。\n",
    "* 精确率定义为：是检索出相关文档数与检索出的文档总数的比率（正确分类的正例个数占分类为正例的实例个数的比例），衡量的是检索系统的查准率。\n",
    "计算公式：$P=\\frac{TP}{TP+FP}$\n",
    "* 召回率定义为：指检索出的相关文档数和文档库中所有的相关文档数的比率（正确分类的正例个数占实际正例个数的比例），衡量的是检索系统的查全率。计算公式：$R=\\frac{TP}{TP+FN}$\n",
    "        * TP-将正类预测为正类数\n",
    "        * FN-将正类预测为负类数\n",
    "        * FP-将负类预测为正类数\n",
    "        * TN-将负类预测为负类数\n",
    "* 另外，`F值`：是精确率和召回率的调和均值，即$F=\\frac{2PR}{P+R}$,当精确率和召回率都高时候，`F值`也会高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树\n",
    "* 决策树(decision tree)是一种基本的分类与回归方法\n",
    "* 决策树模型呈树形结构\n",
    "* 决策树模型可以认为是if-then\n",
    "* 决策树模型也可以认为是定义在特征空间与类空间上的条件概率分布\n",
    "* 优点：分类速度快、模型可读性好\n",
    "\n",
    "### 决策树模型\n",
    "\n",
    "决策树：分类决策树模型是一种描述对实例进行分类的树形结构。\n",
    "* 由结点和有向边组成\n",
    "* 结点类型：内部结点（internal node）和叶结点(leaf node)\n",
    "    * 内部结点：表示一个特征或属性，只有一条入边和多条出边\n",
    "    * 叶结点：表示一个类，有一条入边，但是没有出边\n",
    "    \n",
    "![决策树示例](img/ds.png)\n",
    "* 从决策树的根节点到叶结点的每一条路径构成一条规则\n",
    "    * 路径中内部结点对应着规则的条件\n",
    "    * 叶结点的类对应规则的结论\n",
    "* 例如：$ if 体温=恒温 &&胎生=是 then 该动物是哺乳动物 \n",
    "\n",
    "### 决策树学习的步骤\n",
    "\n",
    "决策树学习包括三个步骤：  \n",
    "* 特征选择\n",
    "* 决策树的生成\n",
    "* 决策树的剪枝\n",
    "\n",
    "### 应用模型\n",
    "\n",
    "![应用模型](img/dsmodel.png)\n",
    "\n",
    "如何训练得到以下决策树：\n",
    "\n",
    "![决策树示例](img/dt.png)\n",
    "\n",
    "得到决策树后，可以进行预测：\n",
    "\n",
    "![决策树预测](img/dt2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树学习——特征选择\n",
    "有很多决策树学习算法：\n",
    "* Hunt’s Algorithm (one of the earliest)\n",
    "* CART\n",
    "* ID3, C4.5\n",
    "* SLIQ,SPRINT\n",
    "\n",
    "大都是采用贪心策略——根据最优化某种标准的属性测试进行记录划分。属性划分的问题是：\n",
    "* 确定如何划分记录?\n",
    "    * 如何指定属性测试条件？\n",
    "    * 如何确定最优划分？\n",
    "* 如何确定何时停止划分？\n",
    "\n",
    "特征选择在于选取对训练数据具有分类能力的特征:\n",
    "* 特征选择决定用哪个特征划分特征空间\n",
    "* 可以提高决策树学习的效率\n",
    "* 如果一个特征进行分类的结果与随机分类的结果没有很大的差别，则这个特征没有分类能力\n",
    "——这种特征扔掉对分类的精度没有太大影响！\n",
    "\n",
    "问题：如何选择最优特征进行分类？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例\n",
    "![示例](img/loan.png)\n",
    "  问题：希望通过所给的训练数据学习一个贷款申请的决策树，用以对未来的贷款申请进行分类，即当新的客户提出贷款申请时，根据申请人的特征利用决策树决定是否批准贷款申请。  \n",
    "       首先，对数据集集合的属性进行标注。  \n",
    "           年龄：0-青年 1-中年 2-老年  \n",
    "           有工作：0-否 1-是  \n",
    "           有自己的房子：0-否  1-是  \n",
    "           信贷情况：0-一般 1-好 2-非常好  \n",
    "           类别（是否放贷）：no-否 yes-是  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择——信息增益\n",
    "![年龄特征](img/age.png)\n",
    "![工作特征](img/work.png)\n",
    "![房子特征](img/housef.png)\n",
    "选择哪个特征划分最好？————利用信息增益  \n",
    "\n",
    "`定义1 熵(entropy)`:表示随机变量不确定性的度量。\n",
    "假如`X`是一个取有限个值的离散随机变量,概率分布为$P(X=x_i)=p_i,i=1,2…,n$\n",
    "熵的定义为：  \n",
    "$$H(X)=-\\sum_{i=1}^{n}p_ilogp_i$$\n",
    "其中，\n",
    "* $p_i=0$,  $0log0=0$\n",
    "* 公式中的对数底数取`2`或`e`,熵的单位分别为比特或纳特\n",
    "* 熵只依赖于`X`的分布，与`X`的取值无关\n",
    "* 熵的值越大，表示随机变量的不确定也越大\n",
    "\n",
    "例如:$P(X=1)=p$，$P(X=0)=1-p$,则：$H(X)=-plog_2p-(1-p)log_2(1-p)$\n",
    "* 当$p=0$或$p=1$时，$H(p)=0$,表示随机变量完全没有不确定性\n",
    "* 当$p=0.5$，熵取值最大，随机变量不确定性最大\n",
    "![熵](img/entropy.png)\n",
    "\n",
    "`定义2 条件熵(Conditional entropy)` $H(Y|X)$:在随机变量`X`的条件下随机变量`Y`的不确定性。定义为`X`给定条件下`Y`的条件概率分布的熵对X的数学期望\n",
    "$$H(Y|X)=\\sum_{i=1}^np_iH(Y|X=x_i)=-\\sum_{x\\in X}\\sum_{y\\in Y}p(x,y)logp(y|x)$$\n",
    "\n",
    "`定义3 联合熵(Joint entropy)` $H(XY)$:两个随机变量同时发生的不确定度。\n",
    "$$H(XY)=\\sum_{(x,y)}p(x,y)logp(x,y)=H(X)+H(Y|X)$$\n",
    "\n",
    "`定义4  信息增益(Information gain)`：表示得知`X`的信息而使得类`Y`的信息的不确定性减少的程度。\n",
    "* 特征`A`对于数据集`D`的信息增益`g(D,A)`：集合`D`的经验熵`H(D)`与给定特征`A`条件下`D`的经验条件熵`H(D|A)`之差，即：\n",
    "$$g(D,A)=H(D)-H(D|A)$$\n",
    "\n",
    "* 熵`H(Y)`与条件熵`H(Y|X)`之差称为`互信息(mutual information)`\n",
    "* 决策树学习中的信息增益等价于训练数据集中类与特征的互信息。\n",
    "\n",
    "#### 信息增益算法\n",
    "已知，训练集`D`，`|D|`表示其样本容量\n",
    "设有`K`个类$C_k$，$k=1,2…K$,$|C_k|$类$C_k$的样本个数，即：\n",
    "$$\\sum_{k=1}^{K}|C_k|=|D|$$\n",
    "设特征$A$有`n`个不同的取值${a_1,a_2,…,a_n}$.根据特征`A`的取值将`D`划分为`n`个子集$D_1,D_2…D_n$,$|D_i|$为$D_i$的样本个数，即：\n",
    "$$\\sum_{i=1}^{n}|D_i|=|D|$$\n",
    "子集$D_i$中属于类$C_k$的样本个集合为$D_{ik}$,即：$D_{ik}=D_i∩C_i$, $|D_{ik}|$为$D_{ik}$的样本个数\n",
    "\n",
    "(1)计算数据集`D`的经验熵`H(D)`\n",
    "$$H(D)=-\\sum_{k=1}^{K}\\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{D}$$\n",
    "(2)计算特征`A`对数据集`D`的经验条件熵`H(D|A)`\n",
    "$$H(D|A)=\\sum_{i=1}^{n}\\frac{|D_i|}{|D|}H(D_i)=-\\sum_{i=1}^{n}\\frac{|D_i|}{|D|}\\sum_{k=1}^{K}\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_i|}$$\n",
    "\n",
    "\n",
    "(3)计算信息增益`g(D,A)`\n",
    "$$g(D,A)=H(D)-H(D|A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例\n",
    "看看贷款的数据集：\n",
    "![贷款示例](img/loan.png)\n",
    "(示例来自于李航《统计学习方法》)  \n",
    "（1）计算经验熵`H(D)`\n",
    "$$H(D)=-\\frac{9}{15}log_2\\frac{9}{15}-\\frac{6}{15}log_2\\frac{6}{15}=0.971$$\n",
    "（2）计算各个特征的信息增益:\n",
    "令 $A_1=年龄$,$A_2=有工作$,$A_3=有房子$,$A_4=信贷情况$  \n",
    "* 对于$A_1$:  \n",
    "$$g(D,A_1)=H(D)-H(D|A_1)=H(D)-[\\frac{5}{15}H(D_1)+\\frac{5}{15}H(D_2)+\\frac{5}{15}H(D_3)$$\n",
    "$$H(D_1)=-\\frac{2}{5}log_2\\frac{2}{5}-\\frac{3}{5}log_2\\frac{3}{5}$$\n",
    "$$H(D_2)=-\\frac{3}{5}log_2\\frac{3}{5}-\\frac{2}{5}log_2\\frac{2}{5}$$\n",
    "$$H(D_3)=-\\frac{4}{5}log_2\\frac{4}{5}-\\frac{1}{5}log_2\\frac{1}{5}$$\n",
    "$$g(D,A_1)=0.971-0.888=0.083$$\n",
    "其中$D_1$，$D_2$，$D_3$分别表示$A_1$取青年、中年和老年时的样本子集。\n",
    "* 对于$A_2$:\n",
    "$$g(D,A_2)=H(D)-H(D|A_2)=H(D)-[\\frac{5}{15}H(D_1)+\\frac{10}{15}H(D_2)]$$\n",
    "$$H(D_1)=0$$\n",
    "$$H(D_2)=-\\frac{4}{10}log_2\\frac{4}{10}-\\frac{6}{10}log_2\\frac{6}{10}$$\n",
    "则，$$g(D,A_1)=0.971-0.647=0.324$$\n",
    "其中$D_1$，$D_2$分别表示示$A_2$取是、否时候的样本子集。\n",
    "* 对于$A_3$:\n",
    "$$g(D,A_3)=H(D)-H(D|A_3)=H(D)-[\\frac{6}{15}*0+\\frac{9}{15}(-\\frac{3}{9}log_2\\frac{3}{9}-\\frac{6}{9}log_2\\frac{6}{9})]=0.971-0.551=0.420$$\n",
    "其中，$D_1$，$D_2$分别表示示$A_3$取是、否时候的样本子集。\n",
    "* 对于$A_4$:\n",
    "$$g(D,A_4)=H(D)-H(D|A_4)=0.971-0.608=0.363$$\n",
    "\n",
    "(3)选择信息增益最大的特征\n",
    "$$g(D,A_1)=0.083$$\n",
    "$$g(D,A_2)=0.324$$\n",
    "$$g(D,A_3)=0.420$$\n",
    "$$g(D,A_4)=0.363$$\n",
    "则，特征$A_3$（有自己的房子）是最优分类特征\n",
    "\n",
    "Note: 用信息增益作为划分训练集的特征，存在偏向于选择取值较多的特征\n",
    "解决办法：利用`信息增益比`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`定义  信息增益比(information gain ratio)`:特征`A`对训练数据集`D`的信息增益比$g_R(D,A)$定义为信息增益$g(D,A)$与训练集`D`关于特征`A`的值的熵`HA(D)`之比，即：\n",
    "$$g_R(D,A)=\\frac{g(D,A)}{H_A(D)}$$\n",
    "$$H_A(D)=-\\sum_{i=1}^{n}\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}$$\n",
    "\n",
    "#### 课后自行练习：\n",
    "利用上例的训练集`D`，计算各特征的信息增益比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 停止分裂的条件\n",
    "* 决策树不可能不限制地生长，为了降低决策树复杂度和提高预测的精度，会适当提前终止节点的分裂。\n",
    "* 停止分裂的一般性条件：\n",
    "    * 最小结点数\n",
    "        * 当节点的数据量小于一个指定的数量时，不继续分裂。两个原因：一是数据量较少时，再做分裂容易强化噪声数据的作用；二是降低树生长的复杂性。\n",
    "        * 提前结束分裂一定程度上有利于降低过拟合的影响。\n",
    "    * 熵或者基尼值小于阈值\n",
    "        * 熵和基尼值的大小表示数据的复杂程度，当熵或者基尼值过小时，表示数据的纯度比较大，如果熵或者基尼值小于一定程度数，节点停止分裂。\n",
    "    * 决策树的深度达到指定的条件\n",
    "    * 所有特征已经停止使用完毕，不能继续进行分裂：被动式停止分裂的条件，当已经没有可分的属性时，直接将当前节点设置为叶子节点。\n",
    "    * 决策树的深度达到指定的条件\n",
    "         * 节点的深度可以理解为节点与决策树根节点的距离，决策树的深度是所有叶子节点的最大深度，当深度到达指定的上限大小时，停止分裂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树生成\n",
    "决策树生成的经典算法：\n",
    "* `ID3`算法\n",
    "* `C4.5`算法\n",
    "两个算法不同点是特征选择的度量不一样:`ID3`采用信息增益来选择，`C4.5`采用信息增益比来选择\n",
    "\n",
    "#### ID3算法\n",
    "ID3算法\n",
    "* 思路：利用信息增益准则选择特征，递归建树。\n",
    "* 方法：\n",
    "    * 从根节点开始，计算所有可能的信息增益\n",
    "    * 选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子节点；\n",
    "    * 再对子节点递归调用以上步骤，建立决策树；\n",
    "    * 终止条件：所有特征的信息增益均很小或没有特征可以选择\n",
    "* 算法描述：\n",
    "    <hr/>\n",
    "     算法：$ID3$算法  \n",
    "    <hr/>\n",
    "    输入：训练集$D$，特征集$A$，阈值$Ԑ$   \n",
    "    \n",
    "    输出：决策树 \n",
    "    \n",
    "    `Step 1`  若`D`中所有实例属于同一类$C_k$，则`T`为单结点树，类$C_k$作为$T$的类标记，返回$T$；    \n",
    "    \n",
    "    `Step 2`  若$A$为空，则$T$为单结点树，并将$D$中数量最多的类$C_k$作为该结点的类，返回$T$    \n",
    "    \n",
    "    `Step 3` 否则，计算A中各特征的对`D`的信息增益，选择信息增益最大的特征$A_g$;\n",
    "    \n",
    "    `Step 4` 如果$A_g$信息增益小于阈值`Ԑ`,则置`T`为单结点树，将`D`中数量最多的类作为该结点的类标记，返回`T`；  \n",
    "    \n",
    "    `Step 5` 否则，对$A_g$的每一个可能值$a_i$,依$A_g=a_i$将$D$分隔成若干个非空子集$D_i$,将$D_i$中实例数最大的类作为标记，构建子节点，由结点及其子结点构成树`T`，返回`T`；  \n",
    "    \n",
    "    `Step 6` 对第`i`个子结点，以$D_i$为训练集，以$A-{A_g}$为特征集，递归调用`Step1~Step5`，得到子树$T_i$,返回$T_i$  \n",
    "    <hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "![贷款示例](img/loantree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树实践\n",
    "\n",
    "通过前面放贷的例子介绍决策树实践."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、创建数据集，返回数据集合dataSet和特征名称的集合label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:08:56.389706Z",
     "start_time": "2019-10-16T03:08:55.972254Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "def createDataSet():\n",
    "    #数据集,也可以将数据集放到文件中，从文件读入\n",
    "    '''\n",
    "    dataSet = [['青年', '否', '否', '一般', 'no'],\n",
    "            ['青年', '否', '否', '好', 'no'],\n",
    "            ['青年', '是', '否', '好', 'yes'],\n",
    "            ['青年', '是', '是', '一般', 'yes'],\n",
    "            ['青年', '否', '否', '一般', 'no'],\n",
    "            ['中年','否', '否', '一般', 'no'],\n",
    "            ['中年', '否', '否', '好', 'no'],\n",
    "            ['中年', '是', '是', '好', 'yes'],\n",
    "            ['中年', '否', '是', '非常好', 'yes'],\n",
    "            ['中年', '否', '是', '非常好', 'yes'],\n",
    "            ['老年', '否', '是', '非常好', 'yes'],\n",
    "            ['老年', '否', '是', '好', 'yes'],\n",
    "            ['老年', '是', '否', '好', 'yes'],\n",
    "            ['老年', '是', '否', '非常好', 'yes'],\n",
    "            ['老年', '否', '否', '一般', 'no']]\n",
    "    labels = ['年龄', '有工作', '有自己的房子', '信贷情况']\n",
    "    '''\n",
    "    dataSet=[[0, 0, 0, 0, 'no'],\n",
    "            [0, 0, 0, 1, 'no'],\n",
    "            [0, 1, 0, 1, 'yes'],\n",
    "            [0, 1, 1, 0, 'yes'],\n",
    "            [0, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 1, 'no'],\n",
    "            [1, 1, 1, 1, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 1, 'yes'],\n",
    "            [2, 1, 0, 1, 'yes'],\n",
    "            [2, 1, 0, 2, 'yes'],\n",
    "            [2, 0, 0, 0, 'no']]\n",
    "    # 特征名称\n",
    "    labels = ['年龄', '有工作', '有自己的房子', '信贷情况']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:38:15.006227Z",
     "start_time": "2019-10-16T03:38:14.984958Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 'no'], [0, 0, 0, 1, 'no'], [0, 1, 0, 1, 'yes'], [0, 1, 1, 0, 'yes'], [0, 0, 0, 0, 'no'], [1, 0, 0, 0, 'no'], [1, 0, 0, 1, 'no'], [1, 1, 1, 1, 'yes'], [1, 0, 1, 2, 'yes'], [1, 0, 1, 2, 'yes'], [2, 0, 1, 2, 'yes'], [2, 0, 1, 1, 'yes'], [2, 1, 0, 1, 'yes'], [2, 1, 0, 2, 'yes'], [2, 0, 0, 0, 'no']]\n",
      "['年龄', '有工作', '有自己的房子', '信贷情况']\n"
     ]
    }
   ],
   "source": [
    "ds,labels=createDataSet()\n",
    "print(ds)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、特征选择——信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:38:16.096100Z",
     "start_time": "2019-10-16T03:38:16.076835Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\"\"\"\n",
    "Function Description：计算给定数据集的熵\n",
    "\n",
    "Parameters:\n",
    "   dataSet-数据集\n",
    "Returns:\n",
    "   ent-经验熵\n",
    "Author:\n",
    "   Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def entropy(dataSet):\n",
    "    #数据集的行数\n",
    "    numberOfData = len(dataSet)\n",
    "    #定义字典存放各类的计数\n",
    "    labelCount = {}\n",
    "    #遍历数据集，对每一类进行计数\n",
    "    for row in dataSet:\n",
    "        #最后一列是类属性\n",
    "        label = row[-1]\n",
    "        #判断当前类在字典是否存在，不存在初始化当前类\n",
    "        if label not in labelCount.keys():\n",
    "            labelCount[label] = 0\n",
    "        #计数\n",
    "        labelCount[label] = labelCount[label] + 1\n",
    "        \n",
    "    ent = 0.0\n",
    "    #计算熵\n",
    "    for key in labelCount:\n",
    "        prob = float(labelCount[key])/numberOfData\n",
    "        ent -= prob * log(prob, 2)\n",
    "        \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:38:16.608854Z",
     "start_time": "2019-10-16T03:38:16.586791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "print(entropy(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算信息增益\n",
    "计算信息增益，需要对按选定特征的每个值对数据集进行划分，然后分别计算对应每个值的条件概率，因此需要定义一个函数对数据集进行划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:38:17.825214Z",
     "start_time": "2019-10-16T03:38:17.805941Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:按给定特征划分数据\n",
    "Parameters:\n",
    "    dataSet-待划分的数据集\n",
    "    col-划分数据的特征\n",
    "    value-对应的特征值\n",
    "Returns:\n",
    "    划分后的数据集\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def splitDataSet(dataSet, col, value):\n",
    "    resultDs = []\n",
    "    #遍历数据集\n",
    "    for row in dataSet:\n",
    "        #当前行指定特征的值\n",
    "        if row[col] == value:\n",
    "                #去掉当前特征\n",
    "                reduceFeatureRow = row[:col]\n",
    "                reduceFeatureRow.extend(row[col+1:])\n",
    "                #将符合条件的值放入到返回的结果集中\n",
    "                resultDs.append(reduceFeatureRow)\n",
    "    return resultDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择最优特征的过程是遍历每一个特征，计算每个特征的信息增益，信息增益最大的特征即为最优特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:38:19.174419Z",
     "start_time": "2019-10-16T03:38:19.147773Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:选择最优特征\n",
    "Parameters:\n",
    "    dataSet-数据集\n",
    "    features-特征的集合\n",
    "Returns:\n",
    "    最优特征对应的列号\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def chooseBestFeature(dataSet, features):\n",
    "    #数据集中的特征个数\n",
    "    numberOfFeature = len(dataSet[0]) - 1\n",
    "    #数据集中数据行的数目\n",
    "    numberOfDataRows = len(dataSet)\n",
    "    #调用求熵的函数entropy来求得数据集的经验熵\n",
    "    origEntropy = entropy(dataSet)\n",
    "    \n",
    "    #定义一个变量记录最大的信息增益\n",
    "    maxInfoGain = 0.0\n",
    "    \n",
    "    #存储最优的选择的特征\n",
    "    selectFeature = -1\n",
    "    \n",
    "    #遍历每一个特征,求每个特征的信息增益\n",
    "    for i in range(numberOfFeature):\n",
    "        \n",
    "        #当前特征的所有取值\n",
    "        featureLst = [row[i] for row in dataSet]\n",
    "        \n",
    "        #转成set,去重\n",
    "        uniqueFeatureSet = set(featureLst)\n",
    "        newEntropy = 0.0\n",
    "        \n",
    "        #遍历当前特征的每一个值，求给定当前特征下的条件熵\n",
    "        for value in uniqueFeatureSet:\n",
    "            #划分数据集\n",
    "            splitDs = splitDataSet(dataSet, i, value)\n",
    "            #求当前取值的概率\n",
    "            prob = len(splitDs) / numberOfDataRows\n",
    "            #求条件熵\n",
    "            newEntropy += prob * entropy(splitDs)\n",
    "        \n",
    "        #计算信息增益\n",
    "        infoGain = origEntropy - newEntropy\n",
    "        \n",
    "        #输出当前特征的信息增益\n",
    "        print(\"第%d特征(%s)的信息增益是%.3f\" % (i, features[i], infoGain))\n",
    "        \n",
    "        #找最大的信息增益\n",
    "        if (infoGain > maxInfoGain):\n",
    "            maxInfoGain = infoGain\n",
    "            selectFeature = i\n",
    "        \n",
    "    #返回最优特征    \n",
    "    return selectFeature  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:38:19.856315Z",
     "start_time": "2019-10-16T03:38:19.832995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0特征(年龄)的信息增益是0.083\n",
      "第1特征(有工作)的信息增益是0.324\n",
      "第2特征(有自己的房子)的信息增益是0.420\n",
      "第3特征(信贷情况)的信息增益是0.363\n",
      "最优特征索引值:2\n"
     ]
    }
   ],
   "source": [
    "print(\"最优特征索引值:\" + str(chooseBestFeature(ds, labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3、创建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:38:28.287554Z",
     "start_time": "2019-10-16T03:38:28.268124Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:统计数量最多类\n",
    "Parameters:\n",
    "    classList-类的集合\n",
    "Returns:\n",
    "    数据最多的类\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def getLabelOfMajor(classList):\n",
    "    #统计classList中每个元素出现的次数\n",
    "    classCount = {}\n",
    "    #遍历每一个类别，统计数量\n",
    "    for label in classList:                                        \n",
    "        if label not in classCount.keys():\n",
    "            classCount[label] = 0   \n",
    "        classCount[label] += 1\n",
    "    #根据字典的值进行降序排列\n",
    "    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    #第一个就是数量最多的类别\n",
    "    return sortedClassCount[0][0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设计递归算法建立决策树 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:07.408796Z",
     "start_time": "2019-10-16T03:42:07.380728Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:递归算法建立决策树\n",
    "Parameters:\n",
    "    dataSet-数据集\n",
    "    labels-特征集合\n",
    "    featLabels - 存储选择的最优特征标签\n",
    "Returns:\n",
    "    创建好的决策树结构\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def createTree(dataSet, labels, featureLabels):\n",
    "    #取分类标签(是否放贷:yes or no)\n",
    "    classList = [row[-1] for row in dataSet] \n",
    "    #结束递归的条件：如果类别完全相同则停止继续划分\n",
    "    if classList.count(classList[0]) == len(classList):         \n",
    "        return classList[0]\n",
    "    #遍历完所有特征时返回出现次数最多的类标签\n",
    "    if len(dataSet[0]) == 1:                                   \n",
    "        return getLabelOfMajor(classList)\n",
    "    \n",
    "    #调用特征选择函数，选择最优特征\n",
    "    bestFeature = chooseBestFeature(dataSet, labels)\n",
    "    bestFeatureLabel = labels[bestFeature]                            \n",
    "    featureLabels.append(bestFeatureLabel)\n",
    "    \n",
    "    #根据最优特征的标签生成树\n",
    "    myTree = {bestFeatureLabel:{}} \n",
    "    #删除已经使用特征标签\n",
    "    del(labels[bestFeature])          \n",
    "    #得到训练集中所有最优特征的属性值\n",
    "    featureValues = [row[bestFeature] for row in dataSet]      \n",
    "    #去掉重复的属性值\n",
    "    uniqueValues = set(featureValues)\n",
    "    #遍历特征，创建决策树\n",
    "    for value in uniqueValues:                                                           \n",
    "        myTree[bestFeatureLabel][value] = createTree(splitDataSet(dataSet, bestFeature, value), labels, featLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:08.053605Z",
     "start_time": "2019-10-16T03:42:08.031429Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0特征(年龄)的信息增益是0.083\n",
      "第1特征(有工作)的信息增益是0.324\n",
      "第2特征(有自己的房子)的信息增益是0.420\n",
      "第3特征(信贷情况)的信息增益是0.363\n",
      "第0特征(年龄)的信息增益是0.252\n",
      "第1特征(有工作)的信息增益是0.918\n",
      "第2特征(信贷情况)的信息增益是0.474\n",
      "{'有自己的房子': {0: {'有工作': {0: 'no', 1: 'yes'}}, 1: 'yes'}}\n"
     ]
    }
   ],
   "source": [
    "featLabels = []\n",
    "myTree = createTree(ds, labels, featLabels)\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4、决策树可视化 （可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:10.579765Z",
     "start_time": "2019-10-16T03:42:10.566903Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:19.087635Z",
     "start_time": "2019-10-16T03:42:19.069989Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:获得叶子结点的数目\n",
    "Parameters:\n",
    "    tree-决策树\n",
    "Returns:\n",
    "    叶子结点的个数\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def getCountOfLeaf(tree):\n",
    "    count = 0\n",
    "    #遍历字典\n",
    "    firstFeature = next(iter(tree))\n",
    "    secondDic = tree[firstFeature]\n",
    "    for key in secondDic.keys():\n",
    "        #如果当前结点的value类型仍然是一个字典，递归调用求结点的数目\n",
    "        if type(secondDic[key]).__name__ == \"dict\":\n",
    "            count += getCountOfLeaf(secondDic[key])\n",
    "        else: #否则是叶子结点，结点数目加1\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:20.865137Z",
     "start_time": "2019-10-16T03:42:20.825413Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:获得决策树的深度\n",
    "Parameters:\n",
    "    tree-决策树\n",
    "Returns:\n",
    "    决策树的深度\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def getTreeDepth(tree):\n",
    "    maxDepth = 0\n",
    "    firstFeature = next(iter(tree))\n",
    "    secondDic = tree[firstFeature]\n",
    "    for key in secondDic.keys():\n",
    "        if type(secondDic[key]).__name__ == \"dict\":\n",
    "            depth = 1 + getTreeDepth(secondDic[key])\n",
    "        else:\n",
    "            depth = 1\n",
    "        if depth > maxDepth:\n",
    "            maxDepth = depth\n",
    "    return maxDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:22.219005Z",
     "start_time": "2019-10-16T03:42:22.199767Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:绘制结点\n",
    "Parameters:\n",
    "    node-结点\n",
    "    position:位置\n",
    "    parent:父亲结点\n",
    "    noteType:结点的类型\n",
    "Returns:\n",
    "    无\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def drawNode(node, position, parent, nodeType):\n",
    "    #定义箭头格式\n",
    "    arrow_args = dict(arrowstyle=\"<-\")     \n",
    "    #设置中文字体\n",
    "    font = FontProperties(fname=\"C:\\\\Windows\\\\Fonts\\\\simkai.ttf\", size=14)  \n",
    "    #绘制结点\n",
    "    createPlot.ax1.annotate(node, xy=parent,  xycoords='axes fraction',    \n",
    "        xytext=position, textcoords='axes fraction',\n",
    "        va=\"center\", ha=\"center\", bbox=nodeType, arrowprops=arrow_args, FontProperties=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:24.342839Z",
     "start_time": "2019-10-16T03:42:24.322172Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:标注边的属性值\n",
    "Parameters:\n",
    "    cntrPt-当前结点\n",
    "    parentPt:父亲结点\n",
    "    txtString:标注的属性值\n",
    "Returns:\n",
    "    无\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def plotMidText(cntrPt, parentPt, txtString):\n",
    "    #计算标注位置 \n",
    "    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0]                     \n",
    "    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1]\n",
    "    font = FontProperties(fname=\"C:\\\\Windows\\\\Fonts\\\\simkai.ttf\", size=14)   \n",
    "    createPlot.ax1.text(xMid, yMid, txtString, va=\"center\", ha=\"center\", rotation=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:26.064336Z",
     "start_time": "2019-10-16T03:42:26.033602Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:绘制决策树\n",
    "Parameters:\n",
    "    myTree-决策树\n",
    "    parentPt:父亲结点\n",
    "    noteTxt:结点文本\n",
    "Returns:\n",
    "    无\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def plotTree(myTree, parentPt, nodeTxt):\n",
    "    #设置结点格式\n",
    "    decisionNode = dict(boxstyle=\"sawtooth\", fc=\"0.8\")    \n",
    "    #设置叶结点格式\n",
    "    leafNode = dict(boxstyle=\"round4\", fc=\"0.8\")  \n",
    "    #获取决策树叶结点数目，决定了树的宽度\n",
    "    numLeafs = getCountOfLeaf(myTree)    \n",
    "    #获取决策树深度\n",
    "    depth = getTreeDepth(myTree)         \n",
    "    #下个字典\n",
    "    firstStr = next(iter(myTree))    \n",
    "    #中心位置\n",
    "    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)   \n",
    "    #标注有向边属性值\n",
    "    plotMidText(cntrPt, parentPt, nodeTxt)       \n",
    "     #绘制结点\n",
    "    drawNode(firstStr, cntrPt, parentPt, decisionNode)\n",
    "    #下一个字典，继续绘制子结点\n",
    "    secondDict = myTree[firstStr]       \n",
    "    #y偏移\n",
    "    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD                                       \n",
    "    for key in secondDict.keys():  \n",
    "         #测试该结点是否为字典，如果不是字典，代表此结点为叶子结点\n",
    "        if type(secondDict[key]).__name__=='dict':  \n",
    "            #不是叶结点，递归调用继续绘制\n",
    "            plotTree(secondDict[key],cntrPt,str(key))                                        \n",
    "        else:              \n",
    "            #如果是叶结点，绘制叶结点，并标注有向边属性值                                             \n",
    "            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW\n",
    "\n",
    "            drawNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)\n",
    "            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))\n",
    "    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:28.470700Z",
     "start_time": "2019-10-16T03:42:28.449169Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:创建绘制面板\n",
    "Parameters:\n",
    "    inTree-决策树\n",
    "Returns:\n",
    "    无\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "   2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def createPlot(inTree):\n",
    "    #创建fig\n",
    "    fig = plt.figure(1, facecolor='white') \n",
    "    #清空fig\n",
    "    fig.clf()                                                                               \n",
    "    axprops = dict(xticks=[], yticks=[])\n",
    "    #去掉x、y轴\n",
    "    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)   \n",
    "    #获取决策树叶结点数目\n",
    "    plotTree.totalW = float(getCountOfLeaf(inTree))  \n",
    "    #获取决策树层数\n",
    "    plotTree.totalD = float(getTreeDepth(inTree)) \n",
    "    #计算x偏移\n",
    "    plotTree.xOff = -0.5/plotTree.totalW\n",
    "    plotTree.yOff = 1.0 \n",
    "    #绘制决策树\n",
    "    plotTree(inTree, (0.5,1.0), '')     \n",
    "    #显示绘制结果\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:42:35.103186Z",
     "start_time": "2019-10-16T03:42:34.664311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0特征(年龄)的信息增益是0.083\n",
      "第1特征(有工作)的信息增益是0.324\n",
      "第2特征(有自己的房子)的信息增益是0.420\n",
      "第3特征(信贷情况)的信息增益是0.363\n",
      "第0特征(年龄)的信息增益是0.252\n",
      "第1特征(有工作)的信息增益是0.918\n",
      "第2特征(信贷情况)的信息增益是0.474\n",
      "{'有自己的房子': {0: {'有工作': {0: 'no', 1: 'yes'}}, 1: 'yes'}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataSet, labels = createDataSet()\n",
    "featLabels = []\n",
    "tree = createTree(dataSet, labels, featLabels)\n",
    "print(tree)  \n",
    "createPlot(tree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5、利用决策树进行预测分类\n",
    "训练好决策树后，需要利用决策树来对新的数据进行预测，也就是将新的数据在决策树上进行搜索的过程，一直搜索到叶子结点，也就获得了该数据的类别信息，可以采用递归的思想来进行在树熵搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:43:19.386123Z",
     "start_time": "2019-10-16T03:43:19.361661Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:利用决策树来预测类别\n",
    "Parameters:\n",
    "    tree-训练好的决策树\n",
    "    featLabels:存储选择的最优特征标签\n",
    "    testVec:测试数据\n",
    "Returns:\n",
    "    返回测试数据的类别信息\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def classify(tree, featLabels, testVec):\n",
    "    #获取决策树结点\n",
    "    firstStr = next(iter(tree))  \n",
    "    #下一个字典\n",
    "    secondDict = tree[firstStr]                                                       \n",
    "    \n",
    "    #获取当前特征的序号\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    \n",
    "    #遍历每一个特征的属性值\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            #如果仍然是字典，则继续递归调用去遍历\n",
    "            if type(secondDict[key]).__name__ == 'dict':\n",
    "                classLabel = classify(secondDict[key], featLabels, testVec)\n",
    "            else: classLabel = secondDict[key]  # 否则就找到该类别信息\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:43:20.283307Z",
     "start_time": "2019-10-16T03:43:20.261517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前数据的类别是：放贷\n"
     ]
    }
   ],
   "source": [
    "testVec = [0,1,0,2]                                        #测试数据\n",
    "result = classify(tree, featLabels, testVec)\n",
    "if result == 'yes':\n",
    "    print('当前数据的类别是：放贷')\n",
    "if result == 'no':\n",
    "    print('当前数据的类别是：不放贷')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6、决策树的存储\n",
    "构造决策树是很耗时的任务，如果数据集很大，将会耗费很多计算时间。然而用创建好的决策树解决分类问题，则可以很快完成。因此，为了节省计算时间，最好能够在每次执行分类时调用已经构造好的决策树。  \n",
    "为了解决这个问题，需要使用Python模块<b>pickle</b>序列化对象。序列化对象可以在磁盘上保存对象，并在需要的时候读取出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:43:23.586381Z",
     "start_time": "2019-10-16T03:43:23.573544Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import pickle\n",
    "\"\"\"\n",
    "Function Description:存储决策树\n",
    "Parameters:\n",
    "    tree-训练好的决策树\n",
    "    filename:存储的文件名\n",
    "Returns:\n",
    "    无\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def storeTree(tree, filename):\n",
    "    with open(filename, 'wb') as fw:\n",
    "        pickle.dump(tree, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:43:25.090837Z",
     "start_time": "2019-10-16T03:43:25.076868Z"
    }
   },
   "outputs": [],
   "source": [
    "storeTree(tree, 'tree.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取存储好的决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:43:26.126348Z",
     "start_time": "2019-10-16T03:43:26.111932Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function Description:读取决策树\n",
    "Parameters:\n",
    "    filename:决策树的存储文件名\n",
    "Returns:\n",
    "    决策树字典\n",
    "Author:\n",
    "    Double Liang\n",
    "Create Date:\n",
    "    2019-10-06\n",
    "Version:\n",
    "    V1.0\n",
    "\"\"\"\n",
    "def readTree(filename):\n",
    "    fr = open(filename, 'rb')\n",
    "    return pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:43:27.517550Z",
     "start_time": "2019-10-16T03:43:27.494923Z"
    }
   },
   "outputs": [],
   "source": [
    "myTree = readTree('tree.txt')\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T03:43:28.402154Z",
     "start_time": "2019-10-16T03:43:28.373835Z"
    }
   },
   "outputs": [],
   "source": [
    "testVec = [0,1,0,2]  #测试数据\n",
    "result = classify(myTree, featLabels, testVec)\n",
    "if result == 'yes':\n",
    "    print('当前数据的类别是：放贷')\n",
    "if result == 'no':\n",
    "    print('当前数据的类别是：不放贷')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一、Step by Step编程实现决策树，掌握决策树分类的原理\n",
    "#### 二、利用一些机器学习包或平台实现决策树，例如：sklearn包\n",
    "参考官方文档：http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 心得\n",
    "#### <font color='red'>书上得来终觉浅，绝知此事要躬行</font>\n",
    "#### 对于一件事情，需要不断的重复做，直到很熟练为止.....编程就是这样的一件事情，没有任何技巧和捷径"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
